{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "043f21a5-1feb-4ede-8ff5-5ffea7d4385c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sam2.build_sam import build_sam2\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import xmltodict\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "\n",
    "torch.autocast(device_type=\"cuda\", dtype=torch.bfloat16).__enter__()\n",
    "if torch.cuda.get_device_properties(0).major >= 8:\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "    \n",
    "checkpoint = \"checkpoints/sam2_hiera_large.pt\"\n",
    "model_cfg = \"sam2_hiera_l.yaml\"\n",
    "predictor = SAM2ImagePredictor(build_sam2(model_cfg, checkpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20a10aa4-f427-43b3-af40-46199082a6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_annotations (data_path):\n",
    "    \"\"\"\n",
    "    Load the annotations extracted from CVAT\n",
    "\n",
    "    Parameters:\n",
    "        path: path to the annotation file which is a xml file\n",
    "    Returns:\n",
    "        The CVAT xml file in a dictionary\n",
    "    \"\"\"\n",
    "    with open(os.path.join(data_path, \"annotations.xml\")) as f:\n",
    "        dataset = xmltodict.parse(f.read())\n",
    "    return dataset\n",
    "\n",
    "def extract_data_from_cvat_annotations (data_path):\n",
    "    \"\"\"\n",
    "    Extract data from CVAT annotation xml file\n",
    "\n",
    "    Parameters:\n",
    "        data_path: path to the annotation file which is a xml file\n",
    "    Returns:\n",
    "        A dictionary of image names, images, bounding boxes and their corresponding classes\n",
    "    \"\"\"\n",
    "    dataset = load_annotations (data_path)\n",
    "    number_of_images = len(dataset['annotations']['image'])\n",
    "    DATA_DICT = dict()\n",
    "    for INDEX in range(number_of_images):\n",
    "        annotations = dataset['annotations']['image'][INDEX]\n",
    "        classes_list = []\n",
    "        image_name = annotations['@name']\n",
    "        img = cv2.imread(os.path.join(data_path, \"images\", image_name))\n",
    "        mask = np.zeros((img.shape[0],img.shape[1]))\n",
    "        try:\n",
    "            image_boxes_data = annotations['box']\n",
    "        except:\n",
    "            image_boxes_data = []\n",
    "        # checks if there is any bounding box in the frame; otherwise it returns an empty mask for that frame without any class names\n",
    "        frame_data_dict= dict()\n",
    "        if len(image_boxes_data)==0:\n",
    "            frame_data_dict.update({\n",
    "                \"image_name\": image_name,\n",
    "                \"img\": img,\n",
    "                \"classes\": [],\n",
    "                \"boxes\": []\n",
    "            })\n",
    "        else:\n",
    "            boxes = [[float(image_boxes_data[j]['@xtl']), float(image_boxes_data[j]['@ytl']), float(image_boxes_data[j]['@xbr']),float(image_boxes_data[j]['@ybr'])] for j in range(len(image_boxes_data))]\n",
    "            labels = [image_boxes_data[j][\"attribute\"]['#text'] for j in range(len(image_boxes_data))]\n",
    "            frame_data_dict.update({\n",
    "                \"image_name\": image_name,\n",
    "                \"img\": img,\n",
    "                \"classes\": labels,\n",
    "                \"boxes\": boxes,\n",
    "            })\n",
    "        DATA_DICT.update({INDEX : frame_data_dict })\n",
    "    return DATA_DICT\n",
    "\n",
    "\n",
    "data_path = \"data\"\n",
    "dataset_dict = extract_data_from_cvat_annotations (data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e82897d6-caf4-4a88-a66b-5c6ef909262d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IVSLab\\Desktop\\sam\\segment-anything-2\\sam2\\modeling\\backbones\\hieradet.py:72: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  x = F.scaled_dot_product_attention(\n"
     ]
    }
   ],
   "source": [
    "out_put_path = \"pseudo_labels\"\n",
    "if not os.path.exists(out_put_path):\n",
    "    os.makedirs(out_put_path)\n",
    "\n",
    "INDEX = 10\n",
    "img_name = dataset_dict[INDEX][\"image_name\"]\n",
    "save_frame_path = os.path.join(out_put_path,img_name[:-4])\n",
    "if not os.path.exists(save_frame_path):\n",
    "    os.mkdir(os.path.join(save_frame_path))\n",
    "cv2.imwrite(os.path.join(save_frame_path,img_name),dataset_dict[INDEX][\"img\"].copy())\n",
    "\n",
    "boxes_ = dataset_dict[INDEX][\"boxes\"]\n",
    "if len(boxes_)==0:\n",
    "    print(\"No bounding box in this frame: \", img_name)\n",
    "    exit # change this to \"continue\" if you have added the loop for all the images\n",
    "classes_ = dataset_dict[INDEX][\"classes\"]\n",
    "unique_class_names = list(np.unique(classes_))\n",
    "for unique_c in unique_class_names:\n",
    "    boxes = [boxes_[index] for index, value in enumerate(classes_) if value == unique_c]\n",
    "    classes = [classes_[index] for index, value in enumerate(classes_) if value == unique_c]\n",
    "    img = dataset_dict[INDEX][\"img\"].copy()\n",
    "    sam_img = img.copy()\n",
    "    mask = np.zeros((img.shape[0],img.shape[1]))\n",
    "    sam_input_points = []\n",
    "    sam_input_labels = []\n",
    "    \n",
    "    ############################################ Sam2 Annotator ############################################\n",
    "    def mouse_callback(event, x, y, flags, param):\n",
    "        global dataset_dict,sam_input_points,sam_input_labels, img, mask, sam_img\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            sam_input_points.append((x, y))\n",
    "            sam_input_labels.append([1])\n",
    "            cv2.circle(img, (x, y), 5, (0, 255, 0), -1)  # Green color for positive points\n",
    "            sam_img =  dataset_dict[INDEX][\"img\"].copy()\n",
    "            predictor.reset_predictor()\n",
    "            predictor.set_image(sam_img)\n",
    "            masks, scores, logits = predictor.predict(\n",
    "                point_coords=np.asarray(sam_input_points),\n",
    "                point_labels=np.asarray(sam_input_labels).reshape(len(sam_input_labels,)),\n",
    "                multimask_output=False)\n",
    "            mask = masks[0]\n",
    "            \n",
    "        elif event == cv2.EVENT_RBUTTONDOWN:\n",
    "            sam_input_points.append((x, y))\n",
    "            sam_input_labels.append([0])\n",
    "            cv2.circle(img, (x, y), 5, (0, 0, 255), -1)  # Red color for negative points\n",
    "            sam_img =  dataset_dict[INDEX][\"img\"].copy()\n",
    "            masks, scores, logits = predictor.predict(\n",
    "                point_coords=np.asarray(sam_input_points),\n",
    "                point_labels=np.asarray(sam_input_labels).reshape(len(sam_input_labels,)),\n",
    "                multimask_output=False)\n",
    "            mask = masks[0].astype(np.uint8) \n",
    "        if len(sam_input_points)!=0:\n",
    "            colored_mask = cv2.cvtColor(mask * 255, cv2.COLOR_GRAY2BGR).astype(np.uint8) \n",
    "            img = cv2.addWeighted(sam_img.copy(), 0.9, colored_mask, 0.7, 0)    \n",
    "        cv2.imshow('Image', img)\n",
    "        \n",
    "    cv2.namedWindow('Image')\n",
    "    cv2.setMouseCallback('Image', mouse_callback)  \n",
    "    while True:\n",
    "        for box in boxes:\n",
    "            img = cv2.rectangle(img, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), (0,0,255),1)\n",
    "        cv2.imshow('Image', img)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == 27:  # ESC key to break\n",
    "            break\n",
    "        if key == ord(\"r\"):\n",
    "            sam_input_points = []\n",
    "            sam_input_labels = []\n",
    "            positive_points = []\n",
    "            negative_points = []\n",
    "    cv2.destroyAllWindows()\n",
    "    ############################################ Editor ############################################\n",
    "    radius = 5\n",
    "    drawing = False\n",
    "    value = 255\n",
    "    # Mouse callback function to edit the mask\n",
    "    def mouse_callback_editor(event, x, y, flags, param):\n",
    "        global alpha,colored_mask,img, mask_, radius, drawing, value\n",
    "    \n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            drawing = True\n",
    "            value = 255\n",
    "            mask_ = cv2.circle(mask_, (x, y), radius, value, -1)\n",
    "            colored_mask = cv2.cvtColor(mask_, cv2.COLOR_GRAY2BGR).astype(np.uint8) \n",
    "            img = cv2.addWeighted(imgg.copy(), alpha, colored_mask, 0.7, 0)    \n",
    "    \n",
    "        elif event == cv2.EVENT_RBUTTONDOWN:\n",
    "            drawing = True\n",
    "            value = 0\n",
    "            mask_ = cv2.circle(mask_, (x, y), radius, value, -1)\n",
    "            colored_mask = cv2.cvtColor(mask_, cv2.COLOR_GRAY2BGR).astype(np.uint8) \n",
    "            img = cv2.addWeighted(imgg.copy(), alpha, colored_mask, 0.7, 0)  \n",
    "        elif event == cv2.EVENT_MOUSEMOVE:\n",
    "            if drawing:\n",
    "                mask_ = cv2.circle(mask_, (x, y), radius, value, -1)\n",
    "                colored_mask = cv2.cvtColor(mask_, cv2.COLOR_GRAY2BGR).astype(np.uint8) \n",
    "                img = cv2.addWeighted(imgg.copy(), alpha, colored_mask, 0.7, 0)  \n",
    "        elif event == cv2.EVENT_LBUTTONUP or event == cv2.EVENT_RBUTTONUP:\n",
    "            drawing = False\n",
    "        cv2.imshow('Mask', img)\n",
    "    \n",
    "    mask_ = (mask*255).astype(np.uint8)\n",
    "    \n",
    "    imgg = dataset_dict[INDEX][\"img\"].copy()\n",
    "    colored_mask = cv2.cvtColor(mask_, cv2.COLOR_GRAY2BGR).astype(np.uint8) \n",
    "    alpha = 0.7\n",
    "    while(True):\n",
    "        img = cv2.addWeighted(imgg.copy(), alpha, colored_mask, 0.7, 0)\n",
    "        cv2.imshow('Mask', img)\n",
    "        cv2.setMouseCallback('Mask', mouse_callback_editor)\n",
    "        key = cv2.waitKey(0) & 0xFF\n",
    "        if key == ord(\"1\"):\n",
    "            radius=10\n",
    "        if key == ord(\"2\"):\n",
    "            radius=20\n",
    "        if key == ord(\"3\"):\n",
    "            radius=30  \n",
    "        if key == ord(\"f\"):\n",
    "            if alpha+0.1<=1:\n",
    "                alpha+=0.1\n",
    "        if key == ord(\"d\"):\n",
    "            if alpha-0.1>=0:\n",
    "                alpha-=0.1\n",
    "        if key == 27:\n",
    "            break\n",
    "    cv2.destroyAllWindows()  \n",
    "    \n",
    "    #################### save results ####################\n",
    "    cv2.imwrite(os.path.join(save_frame_path,unique_c+\".png\"),(mask_).astype(np.uint8))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
